{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain + GPT3.5 For Dependency Extraction\n",
    "\n",
    "### Step 1: Install libraries (if needed), load OPENAI_API_KEY from env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install openai tiktoken langchain\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load Documents\n",
    "- Remove comments \n",
    "- Only process .java files\n",
    "- For \"large\" (>600 token) inputs, we are going to truncate first 1000 characters\n",
    "  - 800 and 1000 are somewhat random\n",
    "  - Truncated size needs to be high enough that we retain imports and ideally main methods (which would typically be defined near the top in java programs)\n",
    "  - Higher truncated size => more cost and time\n",
    "  - With more resources, we could have opted to use CodeLlama or GPT-4 however both options were not available to us\n",
    "  - With more resources we also could have avoided truncating any data and even possibly retain the comments\n",
    "  - In initial tests on a reduced version of flink, we saw optimal inference time and accuracy using these parameters, so that is what we chose to run on the whole system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13219"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "import os \n",
    "import re\n",
    "path = \".\\\\flink-1.17.1\"\n",
    "\n",
    "def remove_comments(code):\n",
    "    # Removing /* ... */ comments\n",
    "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
    "    \n",
    "    # Removing // comments\n",
    "    code = re.sub(r'//.*', '', code)\n",
    "    return code\n",
    "\n",
    "def read_file(file_path):\n",
    "  with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    return f.read()\n",
    "  \n",
    "def load_documents():\n",
    "  documents = []\n",
    "  encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-instruct\")\n",
    "\n",
    "  for dir_path, _, file_names in os.walk(path):\n",
    "    for file_name in file_names:\n",
    "      if file_name.endswith(\".java\"):\n",
    "        content = read_file(dir_path + \"\\\\\" + file_name)\n",
    "        content = remove_comments(content)\n",
    "\n",
    "        while len(encoding.encode(content)) > 800:\n",
    "          content = content[:1000]\n",
    "          \n",
    "        documents.append({\"file_path\": dir_path + \"\\\\\" + file_name, \"source\": content})\n",
    "  return documents\n",
    "\n",
    "documents = load_documents()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': '.\\\\flink-1.17.1\\\\flink-annotations\\\\src\\\\main\\\\java\\\\org\\\\apache\\\\flink\\\\FlinkVersion.java', 'source': '\\n\\npackage org.apache.flink;\\n\\nimport org.apache.flink.annotation.Public;\\n\\nimport java.util.Arrays;\\nimport java.util.LinkedHashSet;\\nimport java.util.Map;\\nimport java.util.Optional;\\nimport java.util.Set;\\nimport java.util.function.Function;\\nimport java.util.stream.Collectors;\\nimport java.util.stream.Stream;\\n\\n\\n@Public\\npublic enum FlinkVersion {\\n\\n    \\n    \\n    \\n    v1_3(\"1.3\"),\\n    v1_4(\"1.4\"),\\n    v1_5(\"1.5\"),\\n    v1_6(\"1.6\"),\\n    v1_7(\"1.7\"),\\n    v1_8(\"1.8\"),\\n    v1_9(\"1.9\"),\\n    v1_10(\"1.10\"),\\n    v1_11(\"1.11\"),\\n    v1_12(\"1.12\"),\\n    v1_13(\"1.13\"),\\n    v1_14(\"1.14\"),\\n    v1_15(\"1.15\"),\\n    v1_16(\"1.16\"),\\n    v1_17(\"1.17\");\\n\\n    private final String versionStr;\\n\\n    FlinkVersion(String versionStr) {\\n        this.versionStr = versionStr;\\n    }\\n\\n    @Override\\n    public String toString() {\\n        return versionStr;\\n    }\\n\\n    public boolean isNewerVersionThan(FlinkVersion otherVersion) {\\n        return this.ordinal() > otherVersion.ordinal();\\n    }\\n\\n    \\n    public static Set<FlinkVersion> rangeOf(FlinkVersion start, FlinkVersion end) {\\n        return Stream.of(FlinkVersion.values())\\n                .filter(v -> v.ordinal() >= start.ordinal() && v.ordinal() <= end.ordinal())\\n                .collect(Collectors.toCollection(LinkedHashSet::new));\\n    }\\n\\n    private static final Map<String, FlinkVersion> CODE_MAP =\\n            Arrays.stream(values())\\n                    .collect(Collectors.toMap(v -> v.versionStr, Function.identity()));\\n\\n    public static Optional<FlinkVersion> byCode(String code) {\\n        return Optional.ofNullable(CODE_MAP.get(code));\\n    }\\n\\n    \\n    public static FlinkVersion current() {\\n        return values()[values().length - 1];\\n    }\\n}\\n'}\n",
      "{'file_path': '.\\\\flink-1.17.1\\\\flink-annotations\\\\src\\\\main\\\\java\\\\org\\\\apache\\\\flink\\\\annotation\\\\Experimental.java', 'source': '\\n\\npackage org.apache.flink.annotation;\\n\\nimport java.lang.annotation.Documented;\\nimport java.lang.annotation.ElementType;\\nimport java.lang.annotation.Target;\\n\\n\\n@Documented\\n@Target({ElementType.TYPE, ElementType.METHOD, ElementType.FIELD, ElementType.CONSTRUCTOR})\\n@Public\\npublic @interface Experimental {}\\n'}\n",
      "{'file_path': '.\\\\flink-1.17.1\\\\flink-annotations\\\\src\\\\main\\\\java\\\\org\\\\apache\\\\flink\\\\annotation\\\\Internal.java', 'source': '\\n\\npackage org.apache.flink.annotation;\\n\\nimport java.lang.annotation.Documented;\\nimport java.lang.annotation.ElementType;\\nimport java.lang.annotation.Target;\\n\\n\\n@Documented\\n@Target({ElementType.TYPE, ElementType.METHOD, ElementType.CONSTRUCTOR, ElementType.FIELD})\\n@Public\\npublic @interface Internal {}\\n'}\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])\n",
    "print(documents[1])\n",
    "print(documents[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define Templates\n",
    "- Retry prompt is used for iterative refinement/feedback prompting\n",
    "- Langchain has a fallback method, but there is no way to track how many times it was called\n",
    "- Thus we will manually do the retry fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "   \n",
    "initial_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Instruction: You will only return valid JSON. Given the following code, extract any internal dependencies. \n",
    "    Output must be a valid JSON array of strings. For the given code you must \n",
    "    determine what external files or packages it depends on, and return them.              \n",
    "    File Path: {file_path}\n",
    "    Code: {source} \n",
    "    Answer in valid JSON: \\n\\n###\\n\\n\"\"\",\n",
    "    input_variables=[\"file_path\", \"source\"]\n",
    ")\n",
    "\n",
    "retry_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    The previous response, \"{response}\" was not valid JSON. Please try again. \n",
    "    Instruction: You will only return valid JSON. Given the following code, extract any internal dependencies. \n",
    "    Output must be a valid JSON array of strings. For the given code you must \n",
    "    determine what external files or packages it depends on, and return them.                    \n",
    "    File Path: {file_path}\n",
    "    Code: {source} \n",
    "    Answer in valid, unformatted JSON: \\n\\n###\\n\\n\"\"\",\n",
    "    input_variables=[\"response\", \"file_path\", \"source\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define response extraction stages\n",
    "- Temperature = 0, tends the model towards being deterministic (less randomness)\n",
    "- Top P = 0.9, ignore the least likely 10% options in prediction (less creative results)\n",
    "- Invoke model calls itself a second time if the JSON parse fails; after the second time we give up and move on\n",
    "- In practice the model never made 2 consecutive errors throughout all ~13200 files\n",
    "- This is largely due to the retry prompt including previous response\n",
    "- LLMs are very good at fixing errors when they are pointed out (few shot prompting for example)\n",
    "- Response is buffered when going through the array in case we run into non-string values. When the code was ran on all of Flink, this did not happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "output = []\n",
    "parse_fails = retry_fails = 0\n",
    "\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\", frequency_penalty=0, presence_penalty=0, top_p=0.9, max_tokens=1000)\n",
    "\n",
    "def invoke_model(document, prev_response=None):\n",
    "    file_path = document[\"file_path\"]\n",
    "    source = document[\"source\"]\n",
    "    is_retry = prev_response is not None\n",
    "\n",
    "    if is_retry:\n",
    "        formatted = retry_prompt.format(file_path=file_path, source=source, response=prev_response)\n",
    "    else: \n",
    "        formatted = initial_prompt.format(file_path=file_path, source=source)\n",
    "\n",
    "    response = llm.invoke(formatted)\n",
    "    response = response.replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "\n",
    "    success = handle_response(file_path, response, is_retry)\n",
    "    if success or (not success and is_retry): \n",
    "        return\n",
    "    else:\n",
    "        invoke_model(document, prev_response=response)\n",
    "\n",
    "            \n",
    "def handle_response(file_path, response, is_retry):\n",
    "    buffered_output = []\n",
    "    try: \n",
    "        parsed = json.loads(response)\n",
    "\n",
    "        for dependency in parsed:\n",
    "            if isinstance(dependency, str):\n",
    "                buffered_output.append((file_path, dependency))\n",
    "            else:\n",
    "                handle_parse_fail(response, \"Dependency was not a string\", is_retry)\n",
    "                return False\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        handle_parse_fail(response, \"Invalid JSON\", is_retry)\n",
    "        return False\n",
    "    \n",
    "    finally:\n",
    "        for item in buffered_output:\n",
    "            output.append(item)\n",
    "        return True\n",
    "\n",
    "\n",
    "def handle_parse_fail(response, msg, is_retry):\n",
    "    global retry_fails, parse_fails\n",
    "\n",
    "    if is_retry:\n",
    "        retry_fails += 1\n",
    "        msg_type = \"Retry\"\n",
    "    else:\n",
    "        parse_fails += 1\n",
    "        msg_type = \"Parse\"\n",
    "        \n",
    "    print(f\"{msg_type} fail ({msg}): {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Process in batches\n",
    "- When doing 13,000+ requests we have a few things to be worried about\n",
    "  - 10k to 100k request rate limit depending on plan tier\n",
    "  - Tokens per minute rate limit\n",
    "  - Any other api errors that might arise\n",
    "- Batch size is modifiable\n",
    "- After each batch we will save the list state to bin\n",
    "- This way if anything fails we can restore manually to a previous state in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126518\n"
     ]
    }
   ],
   "source": [
    "# parse_fails = retry_fails = 0\n",
    "import pickle\n",
    "with open(f\"bin/deps_13219_13221.pkl\", \"rb\") as f:\n",
    "    output = pickle.load(f)\n",
    "\n",
    "print(len(output))\n",
    "batch_start = 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch start: 13219\n",
      "Batch size: 2\n",
      "Parse fails: 311\n",
      "Retry fails: 0\n",
      "Output length: 126518\n",
      "Saved output\n",
      "Start for next run is 13221\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "batch_size = 2\n",
    "batch_end = batch_start + batch_size\n",
    "batch = documents[batch_start:batch_end]\n",
    "\n",
    "# sequential Process\n",
    "for i, document in enumerate(batch):\n",
    "    try:\n",
    "        invoke_model(document)\n",
    "    except Exception as e:\n",
    "        # usually fails due to length so this is an optimistic retry (hopefully API error is just 1 off)\n",
    "        modified_doc = document[\"source\"][:len(document[\"source\"]) // 4] \n",
    "        print(\"API Error [1st]\")\n",
    "        try:\n",
    "            invoke_model(modified_doc)\n",
    "        except Exception as e:\n",
    "            print(\"API Error [2nd]\")\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    display(f\"Iteration: {i}\")\n",
    "\n",
    "\n",
    "# parallel Process -> wont work because rate limit, would have to use small batches and not really going to save much time\n",
    "# if we had an account without rate limit or access to multiple instances of something \n",
    "# like CodeLlama we would be able to do this and save a lot of time\n",
    "\n",
    "\n",
    "# import asyncio\n",
    "\n",
    "# async def async_invoke(prompt):\n",
    "#     resp = await llm.ainvoke(prompt)\n",
    "\n",
    "# async def invoke_model_async(prev_response=None):\n",
    "#     tasks = [async_invoke(llm, initial_prompt.format(file_path=document[\"file_path\"], source=document[\"source\"])) for document in batch]\n",
    "#     for coroutine in asyncio.as_completed(tasks):\n",
    "#         try:\n",
    "#             results = await coroutine\n",
    "#         except Exception as e:\n",
    "#             parse_fails += 1\n",
    "            \n",
    "#             # try a second time...\n",
    "#             try: \n",
    "#                 results_2 = await async_invoke(llm, retry_prompt.format(file_path=document[\"file_path\"], source=document[\"source\"], response=results))\n",
    "#             except Exception as e:\n",
    "#                 retry_fails += 1\n",
    "\n",
    "#         else:\n",
    "#             print('Results:', results)\n",
    "\n",
    "#     await asyncio.gather(*tasks)\n",
    "\n",
    "# await invoke_model_async()\n",
    "\n",
    "print(f\"Batch start: {batch_start}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Parse fails: {parse_fails}\")\n",
    "print(f\"Retry fails: {retry_fails}\")\n",
    "print(f\"Output length: {len(output)}\")\n",
    "\n",
    "# move start (for next run) up to end of batch\n",
    "batch_start = batch_end\n",
    "print(f\"Start for next run is {batch_end}\")\n",
    "\n",
    "# save intermediate state\n",
    "with open(f\"bin/deps_{batch_end - batch_size}_{batch_end}.pkl\", \"wb\") as f:\n",
    "    pickle.dump(output, f)\n",
    "    print(\"Saved output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\flink-1.17.1\\flink-connectors\\flink-connector-files\\src\\test\\java\\org\\apache\\flink\\connector\\file\\table\\stream\\StreamingFileWriterTest.java org.apache.flink.streaming.api.functions.sink.filesystem.OutputFileConfig\n",
      ".\\flink-1.17.1\\flink-connectors\\flink-connector-files\\src\\main\\java\\org\\apache\\flink\\connector\\file\\table\\DefaultPartTimeExtractor.java java.time.LocalTime\n",
      ".\\flink-1.17.1\\flink-table\\flink-table-runtime\\src\\main\\java\\org\\apache\\flink\\table\\runtime\\functions\\BuiltInSpecializedFunction.java org.apache.flink.table.catalog.DataTypeFactory\n",
      ".\\flink-1.17.1\\flink-connectors\\flink-hadoop-compatibility\\src\\test\\java\\org\\apache\\flink\\test\\hadoopcompatibility\\mapred\\HadoopMapredITCase.java org.apache.flink.test.testdata.WordCountData\n",
      ".\\flink-1.17.1\\flink-runtime\\src\\test\\java\\org\\apache\\flink\\runtime\\checkpoint\\channel\\ChannelStateWriteRequestExecutorImplTest.java org.apache.flink.util.function.BiConsumerWithException\n",
      ".\\flink-1.17.1\\flink-table\\flink-table-runtime\\src\\main\\java\\org\\apache\\flink\\table\\runtime\\generated\\GeneratedClass.java org.slf4j.LoggerFactory\n",
      ".\\flink-1.17.1\\flink-state-backends\\flink-statebackend-rocksdb\\src\\main\\java\\org\\apache\\flink\\contrib\\streaming\\state\\EmbeddedRocksDBStateBackend.java org.apache.flink.core.execution.SavepointFormatType\n",
      ".\\flink-1.17.1\\flink-runtime\\src\\test\\java\\org\\apache\\flink\\runtime\\checkpoint\\StandaloneCompletedCheckpointStoreTest.java org.apache.flink.util.concurrent.Executors\n",
      ".\\flink-1.17.1\\flink-runtime\\src\\main\\java\\org\\apache\\flink\\runtime\\checkpoint\\metadata\\MetadataV2V3SerializerBase.java org.apache.flink.runtime.state.KeyGroupRange\n",
      ".\\flink-1.17.1\\flink-tests\\src\\test\\java\\org\\apache\\flink\\test\\scheduling\\PipelinedRegionSchedulingITCase.java org.apache.flink.runtime.io.network.partition.ResultPartitionType\n"
     ]
    }
   ],
   "source": [
    "# pick out random 10 to see if we did things right...\n",
    "import random\n",
    "\n",
    "for x,y in random.sample(output, 10):\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Clean up, write to TA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 120269 uniques\n"
     ]
    }
   ],
   "source": [
    "# clean duplicates\n",
    "output = sorted(set(output))\n",
    "print(f\" {len(output)} uniques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 13194\n",
      "org.apache.flink.FlinkVersion -> .\\flink-1.17.1\\flink-annotations\\src\\main\\java\\org\\apache\\flink\\FlinkVersion.java\n",
      "org.apache.flink.annotation.Experimental -> .\\flink-1.17.1\\flink-annotations\\src\\main\\java\\org\\apache\\flink\\annotation\\Experimental.java\n",
      "org.apache.flink.annotation.Internal -> .\\flink-1.17.1\\flink-annotations\\src\\main\\java\\org\\apache\\flink\\annotation\\Internal.java\n",
      "org.apache.flink.annotation.Public -> .\\flink-1.17.1\\flink-annotations\\src\\main\\java\\org\\apache\\flink\\annotation\\Public.java\n",
      "org.apache.flink.annotation.PublicEvolving -> .\\flink-1.17.1\\flink-annotations\\src\\main\\java\\org\\apache\\flink\\annotation\\PublicEvolving.java\n",
      "org.apache.flink.annotation.VisibleForTesting -> .\\flink-1.17.1\\flink-annotations\\src\\main\\java\\org\\apache\\flink\\annotation\\VisibleForTesting.java\n",
      "org.apache.flink.annotation.docs.ConfigGroup -> .\\flink-1.17.1\\flink-annotations\\src\\main\\java\\org\\apache\\flink\\annotation\\docs\\ConfigGroup.java\n",
      "org.apache.flink.annotation.docs.ConfigGroups -> .\\flink-1.17.1\\flink-annotations\\src\\main\\java\\org\\apache\\flink\\annotation\\docs\\ConfigGroups.java\n",
      "org.apache.flink.annotation.docs.Documentation -> .\\flink-1.17.1\\flink-annotations\\src\\main\\java\\org\\apache\\flink\\annotation\\docs\\Documentation.java\n",
      "org.apache.flink.architecture.common.Conditions -> .\\flink-1.17.1\\flink-architecture-tests\\flink-architecture-tests-base\\src\\main\\java\\org\\apache\\flink\\architecture\\common\\Conditions.java\n"
     ]
    }
   ],
   "source": [
    "# generate map of package -> path where it is defined\n",
    "package_to_path_map = {}\n",
    "\n",
    "for dir_path, _, file_names in os.walk(path):\n",
    "    for file_name in file_names:\n",
    "        if file_name.endswith(\".java\"):\n",
    "            package = dir_path.split(\"\\\\java\\\\\")[-1].replace(\"\\\\\", \".\") + \".\" + file_name.replace(\".java\", \"\")\n",
    "            package_to_path_map[package] = dir_path + \"\\\\\" + file_name\n",
    "            \n",
    "print(f\"Size: {len(package_to_path_map)}\")\n",
    "for k,v in list(package_to_path_map.items())[:10]:\n",
    "    print(k + \" -> \" + v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final output length: 74500\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/FlinkVersion.java flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Public.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Experimental.java flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Public.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Internal.java flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Public.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Public.java flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Public.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/PublicEvolving.java flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Public.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/VisibleForTesting.java flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Internal.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/docs/ConfigGroup.java flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Internal.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/docs/ConfigGroups.java flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Internal.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/docs/ConfigGroups.java flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/docs/ConfigGroup.java\n",
      "flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/docs/Documentation.java flink-1.17.1/flink-annotations/src/main/java/org/apache/flink/annotation/Internal.java\n"
     ]
    }
   ],
   "source": [
    "# apply mapping to depedency list, generate final output (to use for raw ta)\n",
    "final_output = []\n",
    "\n",
    "for source, depdendency in output:\n",
    "    dep_path = package_to_path_map.get(depdendency)\n",
    "    if dep_path is not None:\n",
    "        final_output.append((source[2:].replace(\"\\\\\", \"/\"), dep_path[2:].replace(\"\\\\\", \"/\")))\n",
    "\n",
    "print(f\"Final output length: {len(final_output)}\")\n",
    "for x,y in final_output[:10]:\n",
    "    print(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to TA\n",
    "raw_ta_output = \"./source_raw_ta/llm_dependencies.raw.ta\"\n",
    "\n",
    "with open(raw_ta_output, \"w+\") as f:\n",
    "  f.write(\"FACT TUPLE : \\n\")\n",
    "\n",
    "  unique_file_paths = set(file_path for file_path, _ in final_output)\n",
    "\n",
    "  # first generate all the concrete instances\n",
    "  for file_path in unique_file_paths:\n",
    "    f.write(f\"$INSTANCE {file_path} cFile\\n\")\n",
    "\n",
    "  # now add in all the dependencies\n",
    "  for file_path, dependency in final_output:\n",
    "    f.write(f\"cLinks {file_path} {dependency}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "1. More resources would let us chose a better model (GPT-4 or CodeLlama)\n",
    "\n",
    "2. More resources could also mean less truncation of input files (improve accuracy)\n",
    "\n",
    "3. Batching would still be needed to allow us to work within rate limits \n",
    "\n",
    "4. Batching helped incrementally generate the dependency list with tolerance for failure\n",
    "\n",
    "5. Examples could have been provided to the LLM of hard to recognize dependencies, if those exist (improve accuracy)\n",
    "\n",
    "6. Even without providing examples, we still obtained good performance\n",
    "\n",
    "7. In a more focused environment we could have also finetuned the model prior to use for better performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
